h1. Viewing log files

Trisul has a  rich logging and monitoring framework. This section explains 
# log file locations 
# utilities for viewing log files 
# the 'rat' tool used for in depth monitoring of Trisul Probe pipelines

h2. Log file locations

The three types of log files are 
# domain logs - related to the domain processes that co-ordinate distributed nodes
# application logs - the actual trisul probe and hub logs
# web server logs - web apps 

The locations of these files are :

h3. On the Probe nodes

|_. type |_. what it is |_. default location |_. files |
| Application |  main trisul probe process |  @/usr/local/var/log/trisul-probe/domain0/probe0/context0@  replace the domain, probe, and context with the actual fields if you have created your own contexts | ns-.log - trisul probe logs, xLuaX.log redirected print() statements from LUA script instances |
| Domain | domain processes that co-ordinate nodes |   @/usr/local/var/log/trisul-probe/domain0/probe0@ replace with probe ID. each probe has its own domain processes because they are independent entities even if on the same machine|  cp-XX.log probe logs |

h3. On the Hub nodes

|_. type |_. what it is |_. default location |_. files |
| Application |  trisul-hub Flush process |  @/usr/local/var/log/trisul-hub/domain0/hub0/context0@  replace the domain, hub, and context with the actual values | fs-.log - trisul_flushd database writer logs ,  qs_.log - trisul_trpd TRP database query logs  |
| Domain | domain processes that co-ordinate nodes |   @/usr/local/var/log/trisul-hub/domain0/hub0@ |  cp-XX.log hub logs |
| Domain | domain processes that co-ordinate nodes |   @/usr/local/var/log/trisul-hub/domain0@ |  rt-XX.log domain router log |

h3. On the database


|_. type |_. what it is |_. default location |_. files |
| Application |  Web Trisul webserver log  |  @/usr/local/var/log/trisul-hub/webtrisul@  | production.log - the main webserver log |


h2. Local viewing

The most common scenario is to @tail -f@ the Trisul Probe logs. You can use the aliases defined in @trisbashrc@ to help with this.

* Use @tailf.ns@ alias to tail  probe logs 
* Use @cd.l@ to change directory to the log directory

<pre class="language-bash">
# as root
source /usr/local/share/trisul-probe trisbashrc
tailf.ns

</pre> 

Read about "trisbashrc":/docs/ref/trisbashrc.html aliases

Similarly for the Hub Node

* Use @tailf.fs@ to tail database flusher logs 
* Use @tailf.qs@ to tail database query logs
* Use @cd.l@ to change directory to the log directory
* Use @tailf.ws@ to tail webtrisul logs
* Use @cd.wl@ to change directory to webtrisul log directory


h2. Remote viewing

Using the trisulctl_ tools you can view log files on any node. This is a really powerful feature that even allows you to @tail@ logs on any node. A common use cause is to investigate errors on remote probes from a central hub location.

Say you are on the Hub node and want to view the _ns_ log on probe1 

<pre class="language-bash">
trisulctl_hub
log default@probe1 log=ns       
  # Latest trisul log from probe1 context default


log default@probe1 log=ns tail       
  # Remote tail the log 

</pre> 


Type @help log@ for various example uses.


h2. Rat - Trisul Internals Viewer

RAT is an advanced tool used to monitor internal mechanisms of Trisul Probe. It is mostly used by our developers and field engineers to optimize Trisul Probe for high performance uses. 

To use it 

<pre class="language-bash">

rat <config-file> <filter-type>
 where filter-type is rxring, pfring, afpacket, ffpcap, or lpcap corresponding to the various input modes
</pre>


example

<pre class="language-bash">

rat /usr/local/etc/trisul-probe/domain0/probe0/context0/trisulProbeConfig.xml afpacket

</pre> 

Once rat is up and running you can see the stats of each stage of the filters in the _fast path_ of Trisul Stream Analytics. Press q to quit.


